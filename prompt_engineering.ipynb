{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"voc-232586434104020301899465f0c2fdcc1e25.50297608\"\n",
    "BASE_URL = \"https://openai.vocareum.com/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(base_url=BASE_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  # model=\"gpt-4\",\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a programming assistant with a specialization in logic programming and Prolog. You can interpret complex scenarios and model them in Prolog, and you understand how to verify the correctness of logical assertions using queries.\"},\n",
    "    {\"role\": \"user\", \"content\": \"convert to prolog and check whether the answer is correct \\n I would like the all the lines of code, except the last line, to be run in a .pl file and the last line of code to be a query to validate the answer \\n Please do not answer anything other than code \\n context: There was a group discussion of judicial workers in the city.One group has 8 people.At the beginning of the meeting, the group leader asked everyone if they knew each other.As a result, only one person in the group knew 3 of the group, 3 knew 2 of the group, and 4 knew 1 of the group. \\n question: If the above statistics are true, which of the following conclusions can best be reached?\\n answer: C.Some members may only know what they have seen on television or at a briefing \\n Here is an example: \\n context: Some Cantonese don't like chili, so some southerners don't like chili. \\n question:Which of the following can guarantee the above argument? \\n answer:D.Some Cantonese like neither peppers nor sweets \\n % Define that there is at least one Cantonese who doesn't like chili \\n cantonese(X) :- dislike_chili(X). \\n % If a person is Cantonese and dislikes chili, then there is at least one Southern Chinese who dislikes chili \\n southern_chinese(Y) :- cantonese(Y), dislike_chili(Y). \\n % Define that there is at least one Cantonese who likes neither peppers nor sweets \\n likes_neither_peppers_nor_sweets(X) :- cantonese(X), not(likes_peppers(X)), not(likes_sweets(X)). \\n % Check if the above statement implies that there is at least one Southern Chinese who dislikes chili \\n % (Assuming that liking neither peppers nor sweets implies not liking chili) \\n guarantee_statement(Y) :- likes_neither_peppers_nor_sweets(Y), dislike_chili(Y). \\n % Facts (assuming we have someone who meets the criteria for the answer) \\n cantonese(sam). \\n not(likes_peppers(sam)). \\n not(likes_sweets(sam)). \\n ?- guarantee_statement(Who).\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "# print(completion.choices[0].message)\n",
    "\n",
    "answer = completion.choices[0].message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='cantonese(X) :- dislike_chili(X).\\nsouthern_chinese(Y) :- cantonese(Y), dislike_chili(Y).\\nlikes_neither_peppers_nor_sweets(X) :- cantonese(X), \\\\+ likes_peppers(X), \\\\+ likes_sweets(X).\\nguarantee_statement(Y) :- likes_neither_peppers_nor_sweets(Y), dislike_chili(Y).\\n\\ncantonese(sam).\\n\\\\+ likes_peppers(sam).\\n\\\\+ likes_sweets(sam).\\n\\n?- guarantee_statement(Who).', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_content = answer.content\n",
    "answer_lines = message_content.split('\\n')\n",
    "\n",
    "code_lines = answer_lines[:-1]\n",
    "query_line = answer_lines[-1]\n",
    "\n",
    "# Write code lines to 'test1_gpt3.5.pl' file\n",
    "with open('test1_gpt3.5.pl', 'w') as file:\n",
    "    for line in code_lines:\n",
    "        file.write(line + '\\n')\n",
    "\n",
    "# Append query line to 'query' file\n",
    "with open('query', 'a') as file:\n",
    "    file.write(query_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(df):\n",
    "    context = df.context\n",
    "    question = df.question\n",
    "    answer = df.Answer\n",
    "    return f\"\"\"convert to prolog and check whether the answer is correct \\n I would like the all the lines of code, except the last line, to be run in a .pl file and the last line of code to be a query to validate the answer \\n Please do not answer anything other than code \\n context: {context} \\n question: {question} \\n answer: {answer} \\n Here is an example: \\n context: Some Cantonese don't like chili, so some southerners don't like chili. \\n question:Which of the following can guarantee the above argument? \\n answer:D.Some Cantonese like neither peppers nor sweets \\n % Define that there is at least one Cantonese who doesn't like chili \\n cantonese(X) :- dislike_chili(X). \\n % If a person is Cantonese and dislikes chili, then there is at least one Southern Chinese who dislikes chili \\n southern_chinese(Y) :- cantonese(Y), dislike_chili(Y). \\n % Define that there is at least one Cantonese who likes neither peppers nor sweets \\n likes_neither_peppers_nor_sweets(X) :- cantonese(X), not(likes_peppers(X)), not(likes_sweets(X)). \\n % Check if the above statement implies that there is at least one Southern Chinese who dislikes chili \\n % (Assuming that liking neither peppers nor sweets implies not liking chili) \\n guarantee_statement(Y) :- likes_neither_peppers_nor_sweets(Y), dislike_chili(Y). \\n % Facts (assuming we have someone who meets the criteria for the answer) \\n cantonese(sam). \\n not(likes_peppers(sam)). \\n not(likes_sweets(sam)). \\n ?- guarantee_statement(Who).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('dataset/train.csv')\n",
    "with open('gpt3.5_prolog/query', 'w') as file:\n",
    "    pass  # Simply pass, which empties the file\n",
    "# for i in range(len(test)):\n",
    "for i in range(30):\n",
    "    prompt = get_prompt(test.iloc[i])\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        # model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a programming assistant with a specialization in logic programming and Prolog. You can interpret complex scenarios and model them in Prolog, and you understand how to verify the correctness of logical assertions using queries.\"},\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    answer = completion.choices[0].message\n",
    "    message_content = answer.content\n",
    "    answer_lines = [line for line in message_content.split('\\n') if '```' not in line and line.strip()]\n",
    "\n",
    "    code_lines = answer_lines[:-1]\n",
    "    query_line = answer_lines[-1]\n",
    "\n",
    "    filename = f\"gpt3.5_prolog/test{i+1}_gpt3.5.pl\"\n",
    "    with open(filename, 'w') as file:\n",
    "        for line in code_lines:\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "    with open('gpt3.5_prolog/query', 'a') as file:\n",
    "        file.write(query_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.717948717948718, Accuracy: 0.5925925925925926, Precision: 0.5833333333333334, Recall: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions = []\n",
    "result_file_path = 'gpt3.5_prolog/prolog_results.txt'\n",
    "label_file_path = 'dataset/train.csv'\n",
    "with open(result_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        predictions.append(int(line.strip()))\n",
    "\n",
    "test = pd.read_csv(label_file_path)\n",
    "labels = test['Label'].tolist()[:len(predictions)]\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "f1 = f1_score(labels, predictions)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "precision = precision_score(labels, predictions)\n",
    "recall = recall_score(labels, predictions)\n",
    "print(f'F1: {f1}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
