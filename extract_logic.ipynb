{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:992)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:992)>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('dataset/train.csv')\n",
    "\n",
    "# Define a preprocessing function\n",
    "def preprocess(text):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Apply stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "    \n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "# Apply preprocessing to a specific column (adjust 'text_column' to your column name)\n",
    "df['processed_context'] = df['context'].apply(preprocess)\n",
    "df['processed_question'] = df['question'].apply(preprocess)\n",
    "df['processed_answer'] = df['Answer'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    # Use the pooled output for sentence-level representation\n",
    "    embeddings = outputs.pooler_output\n",
    "    return embeddings.detach().numpy()\n",
    "\n",
    "# Apply BERT embeddings extraction to each preprocessed column\n",
    "df['bert_context'] = df['processed_context'].apply(get_bert_embedding)\n",
    "df['bert_question'] = df['processed_question'].apply(get_bert_embedding)\n",
    "df['bert_answer'] = df['processed_answer'].apply(get_bert_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bert_answer'] = df['processed_answer'].apply(get_bert_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Label</th>\n",
       "      <th>processed_context</th>\n",
       "      <th>processed_question</th>\n",
       "      <th>processed_answer</th>\n",
       "      <th>context_logical_markers</th>\n",
       "      <th>question_logical_markers</th>\n",
       "      <th>answer_logical_markers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Some Cantonese don't like chili, so some south...</td>\n",
       "      <td>Which of the following can guarantee the above...</td>\n",
       "      <td>D.Some Cantonese like neither peppers nor sweets</td>\n",
       "      <td>0</td>\n",
       "      <td>cantones n't like chili , southern n't like ch...</td>\n",
       "      <td>follow guarante argument ?</td>\n",
       "      <td>d.some cantones like neither pepper sweet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Continuous exposure to indoor fluorescent ligh...</td>\n",
       "      <td>Which of the following questions was the initi...</td>\n",
       "      <td>A.Can hospital light therapy be proved to prom...</td>\n",
       "      <td>1</td>\n",
       "      <td>continu exposur indoor fluoresc light benefici...</td>\n",
       "      <td>follow question initi motiv conduct experi ?</td>\n",
       "      <td>a.can hospit light therapi prove promot patien...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There is no doubt that minors should be prohib...</td>\n",
       "      <td>In order to evaluate the above argument, which...</td>\n",
       "      <td>B.How much inconvenience does the ban on the u...</td>\n",
       "      <td>1</td>\n",
       "      <td>doubt minor prohibit smoking.howev , explicitl...</td>\n",
       "      <td>order evalu argument , follow question import ?</td>\n",
       "      <td>b.how much inconveni ban use automat vend mach...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A research report states that a special educat...</td>\n",
       "      <td>Which of the following best illustrates the lo...</td>\n",
       "      <td>B.Establishing such education and training pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>research report state special educ program chi...</td>\n",
       "      <td>follow best illustr logic loophol summar ?</td>\n",
       "      <td>b.establish educ train program nation basi req...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The traitor is a traitor, so you are a traitor...</td>\n",
       "      <td>Which of the following makes the same logical ...</td>\n",
       "      <td>C.The earth is a sphere, which can be proved f...</td>\n",
       "      <td>1</td>\n",
       "      <td>traitor traitor , traitor , patriot.th word pa...</td>\n",
       "      <td>follow make logic mistak ?</td>\n",
       "      <td>c.the earth sphere , prove fact stand height w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7371</th>\n",
       "      <td>A warehouse was stolen.After investigation, it...</td>\n",
       "      <td>Now suppose that only one of the four people s...</td>\n",
       "      <td>C.C is the criminal who steals the warehouse.</td>\n",
       "      <td>0</td>\n",
       "      <td>warehous stolen.aft investig , ascertain zuomo...</td>\n",
       "      <td>suppos one four peopl spoke truth.then</td>\n",
       "      <td>c.c crimin steal warehous .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>A warehouse was stolen.After investigation, it...</td>\n",
       "      <td>Now suppose that only one of the four people c...</td>\n",
       "      <td>A.A is a criminal who steals a warehouse.</td>\n",
       "      <td>0</td>\n",
       "      <td>warehous stolen.aft investig , ascertain zuomo...</td>\n",
       "      <td>suppos one four peopl confess falsehood.then</td>\n",
       "      <td>a.a crimin steal warehous .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7373</th>\n",
       "      <td>The three members A.B, and C discuss the meani...</td>\n",
       "      <td>The following conclusion is correct?</td>\n",
       "      <td>D.B's opinion is correct, A and C's opinion is...</td>\n",
       "      <td>1</td>\n",
       "      <td>three member a.b , c discuss mean principl `` ...</td>\n",
       "      <td>follow conclus correct ?</td>\n",
       "      <td>d.b 's opinion correct , c 's opinion incorrect .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374</th>\n",
       "      <td>In a restaurant, all dishes are either Sichuan...</td>\n",
       "      <td>Which of the following can enhance the above a...</td>\n",
       "      <td>A.The restaurant stipulates that when ordering...</td>\n",
       "      <td>1</td>\n",
       "      <td>restaur , dish either sichuan cuisin cantones ...</td>\n",
       "      <td>follow enhanc argument ?</td>\n",
       "      <td>a.th restaur stipul order cantones cuisin , or...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7375</th>\n",
       "      <td>There is overlap in a certain department, and ...</td>\n",
       "      <td>This practice led by the department indicates.</td>\n",
       "      <td>C.With the streamlining agency office, it is p...</td>\n",
       "      <td>0</td>\n",
       "      <td>overlap certain depart , peopl indifferent.in ...</td>\n",
       "      <td>practic led depart indic .</td>\n",
       "      <td>c.with streamlin agenc offic , possibl better ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7376 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0     Some Cantonese don't like chili, so some south...   \n",
       "1     Continuous exposure to indoor fluorescent ligh...   \n",
       "2     There is no doubt that minors should be prohib...   \n",
       "3     A research report states that a special educat...   \n",
       "4     The traitor is a traitor, so you are a traitor...   \n",
       "...                                                 ...   \n",
       "7371  A warehouse was stolen.After investigation, it...   \n",
       "7372  A warehouse was stolen.After investigation, it...   \n",
       "7373  The three members A.B, and C discuss the meani...   \n",
       "7374  In a restaurant, all dishes are either Sichuan...   \n",
       "7375  There is overlap in a certain department, and ...   \n",
       "\n",
       "                                               question  \\\n",
       "0     Which of the following can guarantee the above...   \n",
       "1     Which of the following questions was the initi...   \n",
       "2     In order to evaluate the above argument, which...   \n",
       "3     Which of the following best illustrates the lo...   \n",
       "4     Which of the following makes the same logical ...   \n",
       "...                                                 ...   \n",
       "7371  Now suppose that only one of the four people s...   \n",
       "7372  Now suppose that only one of the four people c...   \n",
       "7373               The following conclusion is correct?   \n",
       "7374  Which of the following can enhance the above a...   \n",
       "7375     This practice led by the department indicates.   \n",
       "\n",
       "                                                 Answer  Label  \\\n",
       "0      D.Some Cantonese like neither peppers nor sweets      0   \n",
       "1     A.Can hospital light therapy be proved to prom...      1   \n",
       "2     B.How much inconvenience does the ban on the u...      1   \n",
       "3     B.Establishing such education and training pro...      0   \n",
       "4     C.The earth is a sphere, which can be proved f...      1   \n",
       "...                                                 ...    ...   \n",
       "7371      C.C is the criminal who steals the warehouse.      0   \n",
       "7372          A.A is a criminal who steals a warehouse.      0   \n",
       "7373  D.B's opinion is correct, A and C's opinion is...      1   \n",
       "7374  A.The restaurant stipulates that when ordering...      1   \n",
       "7375  C.With the streamlining agency office, it is p...      0   \n",
       "\n",
       "                                      processed_context  \\\n",
       "0     cantones n't like chili , southern n't like ch...   \n",
       "1     continu exposur indoor fluoresc light benefici...   \n",
       "2     doubt minor prohibit smoking.howev , explicitl...   \n",
       "3     research report state special educ program chi...   \n",
       "4     traitor traitor , traitor , patriot.th word pa...   \n",
       "...                                                 ...   \n",
       "7371  warehous stolen.aft investig , ascertain zuomo...   \n",
       "7372  warehous stolen.aft investig , ascertain zuomo...   \n",
       "7373  three member a.b , c discuss mean principl `` ...   \n",
       "7374  restaur , dish either sichuan cuisin cantones ...   \n",
       "7375  overlap certain depart , peopl indifferent.in ...   \n",
       "\n",
       "                                   processed_question  \\\n",
       "0                          follow guarante argument ?   \n",
       "1        follow question initi motiv conduct experi ?   \n",
       "2     order evalu argument , follow question import ?   \n",
       "3          follow best illustr logic loophol summar ?   \n",
       "4                          follow make logic mistak ?   \n",
       "...                                               ...   \n",
       "7371           suppos one four peopl spoke truth.then   \n",
       "7372     suppos one four peopl confess falsehood.then   \n",
       "7373                         follow conclus correct ?   \n",
       "7374                         follow enhanc argument ?   \n",
       "7375                       practic led depart indic .   \n",
       "\n",
       "                                       processed_answer  \\\n",
       "0             d.some cantones like neither pepper sweet   \n",
       "1     a.can hospit light therapi prove promot patien...   \n",
       "2     b.how much inconveni ban use automat vend mach...   \n",
       "3     b.establish educ train program nation basi req...   \n",
       "4     c.the earth sphere , prove fact stand height w...   \n",
       "...                                                 ...   \n",
       "7371                        c.c crimin steal warehous .   \n",
       "7372                        a.a crimin steal warehous .   \n",
       "7373  d.b 's opinion correct , c 's opinion incorrect .   \n",
       "7374  a.th restaur stipul order cantones cuisin , or...   \n",
       "7375  c.with streamlin agenc offic , possibl better ...   \n",
       "\n",
       "      context_logical_markers  question_logical_markers  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "...                       ...                       ...   \n",
       "7371                        0                         0   \n",
       "7372                        0                         0   \n",
       "7373                        0                         0   \n",
       "7374                        0                         0   \n",
       "7375                        0                         0   \n",
       "\n",
       "      answer_logical_markers  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "...                      ...  \n",
       "7371                       0  \n",
       "7372                       0  \n",
       "7373                       0  \n",
       "7374                       0  \n",
       "7375                       0  \n",
       "\n",
       "[7376 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_logical_markers(text):\n",
    "    # Define a set of logical markers\n",
    "    logical_markers = {\n",
    "        'because', 'therefore', 'if', 'then', 'not', 'never'\n",
    "    }\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Count the occurrences of each logical marker in the text\n",
    "    return sum(token in logical_markers for token in tokens)\n",
    "\n",
    "# Apply the function to each preprocessed text column\n",
    "df['context_logical_markers'] = df['processed_context'].apply(count_logical_markers)\n",
    "df['question_logical_markers'] = df['processed_question'].apply(count_logical_markers)\n",
    "df['answer_logical_markers'] = df['processed_answer'].apply(count_logical_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bert_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/630/Project/Logical_Classification/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bert_context'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert_context\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert_question\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert_answer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext_logical_markers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion_logical_markers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manswer_logical_markers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/630/Project/Logical_Classification/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/630/Project/Logical_Classification/.venv/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/630/Project/Logical_Classification/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/Documents/630/Project/Logical_Classification/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: np\u001b[38;5;241m.\u001b[39mconcatenate([\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert_context\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m      5\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert_question\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert_answer\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m     np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m      8\u001b[0m         row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_logical_markers\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      9\u001b[0m         row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion_logical_markers\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     10\u001b[0m         row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer_logical_markers\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m     ])\n\u001b[1;32m     12\u001b[0m ]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/630/Project/Logical_Classification/.venv/lib/python3.11/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/Documents/630/Project/Logical_Classification/.venv/lib/python3.11/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/Documents/630/Project/Logical_Classification/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bert_context'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['combined_features'] = df.apply(lambda row: np.concatenate([\n",
    "    row['bert_context'],\n",
    "    row['bert_question'],\n",
    "    row['bert_answer'],\n",
    "    np.array([\n",
    "        row['context_logical_markers'],\n",
    "        row['question_logical_markers'],\n",
    "        row['answer_logical_markers']\n",
    "    ])\n",
    "]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(df):\n",
    "    context = df.context\n",
    "    question = df.question\n",
    "    answer = df.Answer\n",
    "    return f\"\"\"Given that \"{context}\", do you think this is logically correct: \"{answer}\".\n",
    "Answer 1 if it is correct, otherwise answer 0. Your answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../dataset/test.csv')\n",
    "# for i in range(len(test)):\n",
    "for i in range(10):\n",
    "    prompt = get_prompt(test.iloc[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
