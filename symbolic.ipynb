{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'extract_logic' from 'deep_logic' (/Users/mac/Documents/630/Project/Logical_Classification/.venv/lib/python3.11/site-packages/deep_logic/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeep_logic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_logic\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Example text\u001b[39;00m\n\u001b[1;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf it rains, the ground gets wet. It is raining. Therefore, the ground is wet.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'extract_logic' from 'deep_logic' (/Users/mac/Documents/630/Project/Logical_Classification/.venv/lib/python3.11/site-packages/deep_logic/__init__.py)"
     ]
    }
   ],
   "source": [
    "from deep_logic import extract_logic\n",
    "\n",
    "# Example text\n",
    "text = \"If it rains, the ground gets wet. It is raining. Therefore, the ground is wet.\"\n",
    "\n",
    "# Extract logic\n",
    "logic_output = extract_logic(text)\n",
    "\n",
    "# Print the extracted logic\n",
    "print(logic_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import deep_logic as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1185a2fb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)   \n",
    "torch.manual_seed(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor([\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 1, 0, 1],\n",
    "    [1, 0, 0, 1],\n",
    "    [1, 1, 0, 1],\n",
    "], dtype=torch.float)\n",
    "y_train = torch.tensor([0, 1, 1, 0], dtype=torch.float).unsqueeze(1)\n",
    "xnp = x_train.detach().numpy()\n",
    "ynp = y_train.detach().numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    torch.nn.Linear(x_train.size(1), 10),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(10, 4),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(4, 1),\n",
    "    torch.nn.Sigmoid(),\n",
    "]\n",
    "model = torch.nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'deep_logic' has no attribute 'validate_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_data\u001b[49m(x_train)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'deep_logic' has no attribute 'validate_data'"
     ]
    }
   ],
   "source": [
    "dl.validate_data(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_version', 'concept_extractor', 'logic', 'models', 'nn', 'utils']\n"
     ]
    }
   ],
   "source": [
    "print(dir(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conv2Concepts', 'XLinear', 'XLogic', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'concepts', 'linear', 'logic']\n"
     ]
    }
   ],
   "source": [
    "print(dir(dl.nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'base', 'loss', 'metrics', 'relu_nn', 'selection']\n"
     ]
    }
   ],
   "source": [
    "print(dir(dl.utils))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train accuracy: 1.0000\n",
      "Epoch 100: train accuracy: 1.0000\n",
      "Epoch 200: train accuracy: 1.0000\n",
      "Epoch 300: train accuracy: 1.0000\n",
      "Epoch 400: train accuracy: 1.0000\n",
      "Epoch 500: train accuracy: 1.0000\n",
      "Pruned 0/4 features\n",
      "Pruned 2/4 features\n",
      "Epoch 600: train accuracy: 1.0000\n",
      "Epoch 700: train accuracy: 1.0000\n",
      "Epoch 800: train accuracy: 1.0000\n",
      "Epoch 900: train accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "need_pruning = True\n",
    "for epoch in range(1000):\n",
    "    # forward pass\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    # Compute Loss\n",
    "    loss = torch.nn.functional.binary_cross_entropy(y_pred, y_train)\n",
    "    # A bit of L1 regularization will encourage sparsity\n",
    "    for module in model.children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            loss += 0.001 * torch.norm(module.weight, 1)\n",
    "\n",
    "    # We can use sparsity to prune dummy features\n",
    "    if epoch > 500 and need_pruning:\n",
    "        # dl.utils.relu_nn.prune_features(model, n_classes)\n",
    "        dl.utils.relu_nn.prune_features(model, n_classes=2)\n",
    "        need_pruning = False\n",
    "\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # compute accuracy\n",
    "    if epoch % 100 == 0:\n",
    "        y_pred_d = (y_pred > 0.5)\n",
    "        accuracy = (y_pred_d.eq(y_train).sum(dim=1) == y_train.size(1)).sum().item() / y_train.size(0)\n",
    "        print(f'Epoch {epoch}: train accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m explanation \u001b[38;5;241m=\u001b[39m dl\u001b[38;5;241m.\u001b[39mlogic\u001b[38;5;241m.\u001b[39mexplain_local(model, x_train, y_train, x_sample\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      2\u001b[0m                                     \u001b[38;5;66;03m#  x_sample=\u001b[39;00m\n\u001b[1;32m      3\u001b[0m                                      method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpruning\u001b[39m\u001b[38;5;124m'\u001b[39m, target_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                      concept_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(explanation)\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "explanation = dl.logic.explain_local(model, x_train, y_train, x_sample=torch.tensor([x_train[1], y_train[1]]),\n",
    "                                    #  x_sample=\n",
    "                                     method='pruning', target_class=1,\n",
    "                                     concept_names=['f1', 'f2', 'f3', 'f4'])\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m explanation \u001b[38;5;241m=\u001b[39m dl\u001b[38;5;241m.\u001b[39mlogic\u001b[38;5;241m.\u001b[39mexplain_local(model, x_train, y_train, x_sample\u001b[38;5;241m=\u001b[39m\u001b[43mx\u001b[49m[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      2\u001b[0m                                      method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpruning\u001b[39m\u001b[38;5;124m'\u001b[39m, target_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                      concept_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(explanation)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "explanation = dl.logic.explain_local(model, x_train, y_train, x_sample=x[1],\n",
    "                                     method='pruning', target_class=1,\n",
    "                                     concept_names=['f1', 'f2', 'f3', 'f4'])\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lens\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# lens.utils.base.set_seed(0)\n",
    "x = torch.rand([100, 4])\n",
    "y = (x[:, 0] > 0.5) & (x[:, 1] < 0.5) | \\\n",
    "    (x[:, 0] < 0.5) & (x[:, 1] > 0.5)\n",
    "\n",
    "data = torch.utils.data.TensorDataset(x, y)\n",
    "\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(data, [80, 10, 10])\n",
    "x_train, y_train = data[train_data.indices]\n",
    "x_val, y_val = data[val_data.indices]\n",
    "x_test, y_test = data[test_data.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'lens' has no attribute 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mXMuNN(n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m      2\u001b[0m                           hidden_neurons\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m10\u001b[39m], loss\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'lens' has no attribute 'models'"
     ]
    }
   ],
   "source": [
    "model = lens.models.XMuNN(n_classes=2, n_features=4,\n",
    "                          hidden_neurons=[10], loss=torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, val_data, epochs=100, l_r=0.1)\n",
    "\n",
    "## get accuracy on test samples\n",
    "test_acc = model.evaluate(test_data)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get first order logic explanations for a specific target class\n",
    "target_class = 1\n",
    "concept_names = ['x1', 'x2', 'x3', 'x4']\n",
    "formula = model.get_global_explanation(x_train, y_train, target_class,\n",
    "                                       top_k_explanations=2, concept_names=concept_names)\n",
    "print(f\"{formula} <-> f{target_class}\")\n",
    "\n",
    "## compute explanation accuracy\n",
    "exp_accuracy, _ = lens.logic.test_explanation(formula, target_class, x_test, y_test,\n",
    "                                              concept_names=concept_names)\n",
    "print(\"Logic Test Accuracy:\", exp_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
